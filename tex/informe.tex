\documentclass[a4paper, 10pt, twoside]{article}

\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[spanish, es-ucroman, es-noquoting]{babel}
\usepackage{setspace}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{verbatim}
\usepackage{fancyvrb}
\usepackage{graphicx}
\usepackage{float}
\usepackage{enumitem} % Provee macro \setlist
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{xspace}
\usepackage{makeidx}
\usepackage[toc, page]{appendix}

\makeindex

%%%%%%%%%% Constantes - Inicio %%%%%%%%%%
\newcommand{\titulo}{Trabajo Práctico 2}
\newcommand{\materia}{Bases de Datos}
\newcommand{\integrantes}{Delgado · Lovisolo · Petaccio · Rebecchi}
\newcommand{\cuatrimestre}{Segundo Cuatrimestre de 2014}
%%%%%%%%%% Constantes - Fin %%%%%%%%%%


%%%%%%%%%% Configuración de Fancyhdr - Inicio %%%%%%%%%%
\pagestyle{fancy}
\thispagestyle{fancy}
\lhead{\titulo\ · \materia}
\rhead{\integrantes}
\renewcommand{\footrulewidth}{0.4pt}
\cfoot{\thepage /\pageref{LastPage}}

\fancypagestyle{caratula} {
   \fancyhf{}
   \cfoot{\thepage /\pageref{LastPage}}
   \renewcommand{\headrulewidth}{0pt}
   \renewcommand{\footrulewidth}{0pt}
}
%%%%%%%%%% Configuración de Fancyhdr - Fin %%%%%%%%%%


%%%%%%%%%% Insertar gráfico - Inicio %%%%%%%%%%
\newcommand{\grafico}[3]{
  \begin{figure}[H]
    \includegraphics[type=pdf,ext=.pdf,read=.pdf]{#1}
    \caption{#2}
    \label{#3}
  \end{figure}
}
%%%%%%%%%% Insertar gráfico - Fin %%%%%%%%%%


%%%%%%%%%% Miscelánea - Inicio %%%%%%%%%%
% Evita que el documento se estire verticalmente para ocupar el espacio vacío
% en cada página.
\raggedbottom

% Separación entre párrafos.
\setlength{\parskip}{0.5em}

% Separación entre elementos de listas.
\setlist{itemsep=0.5em}

% Asigna la traducción de la palabra 'Appendices'.
\renewcommand{\appendixtocname}{Apéndices}
\renewcommand{\appendixpagename}{Apéndices}
%%%%%%%%%% Miscelánea - Fin %%%%%%%%%%


\begin{document}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Carátula                                                                   %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\thispagestyle{caratula}

\begin{center}

\includegraphics[height=2cm]{DC.png} 
\hfill
\includegraphics[height=2cm]{UBA.jpg} 

\vspace{2cm}

Departamento de Computación,\\
Facultad de Ciencias Exactas y Naturales,\\
Universidad de Buenos Aires

\vspace{4cm}

\begin{Huge}
\titulo
\end{Huge}

\vspace{0.5cm}

\begin{Large}
\materia
\end{Large}

\vspace{1cm}

\cuatrimestre

\vspace{4cm}

\begin{tabular}{|c|c|c|}
\hline
Apellido y Nombre & LU & E-mail\\
\hline
Delgado, Alejandro N.  & 601/11 & nahueldelgado@gmail.com\\
Lovisolo, Leandro      & 645/11 & leandro@leandro.me\\
Petaccio, Lautaro José & 443/11 & lausuper@gmail.com\\
Rebecchi, Alejandro    & 15/10  & alejandrorebecchi@gmail.com\\
\hline
\end{tabular}

\end{center}

\newpage

\printindex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Introducción                                                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Introducción}

Este trabajo introduce tres estimadores de selectividad distintos, Classic Histogram, Distribution Steps provistos 
por el paper\footnote{G. Piatetsky-Shapiro and C. Connell. Accurate estimation of the number of tuples satisfying
a condition. Proc. of ACM SIGMOD Conf. pages 256-276, 1984} otorgado por la cátedra y Estimador Grupo creado por 
los participantes del trabajo. El trabajo presenta un análisis teórico y empírico del comportamiento de estos 
estimadores ante diferentes situaciones y presenta los resultados y conclusiones de los mismos.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Estimadores                                                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Estimadores}

\subsection{Classic Histogram}

Este estimador se basa en un modelo de histograma en el cual cada barra representa un rango
de valores del mismo tamaño.
Es decir, al inicializar el estimador, se le pasa como parámetro el numero de barras que se
desea que tenga el histograma
y luego se utiliza dicho valor para dividir el rango de valores en partes iguales.
Esto se realiza al inicializar el estimador en la función \textit{build\_struct}, la cual a su vez delega esta tarea
a otras 3 funciones:
\begin{itemize}
\item \textbf{compute\_range}: La cual calcula la cantidad de valores que abarcará cada barra. Al conjunto de valores asociado
a cada barra lo llamamos \textit{bucket} y la cantidad de elementos que contiene \textit{step}.
\begin{verbatim}
    def compute_range(self):
    	#evita que haya mas buckets que valores
        self.num_buckets = min(self.parameter, self.max - self.min + 1)
        self.step        = float(self.max - self.min) / self.num_buckets
\end{verbatim}
\item \textbf{compute\_bucket\_ranges} En donde se calcula para cada barra, los límites del intervalo de valores
que abarca.
\begin{verbatim}
    def compute_bucket_ranges(self):
        for i in [0..self.num_buckets):
            low  = self.min + int(self.step * i)
            high = self.min + int(self.step * (i + 1)) - 1
            if i == self.num_buckets - 1:
                high = self.max
            bucket_ranges[i] = (low, high)
\end{verbatim}
\item \textbf{compute\_buckets} Se encarga de computar para cada intervalo la cantidad de registros cuyo valor está dentro del mismo.   
\end{itemize}
\begin{verbatim}
    def compute_buckets(self):
        for range in self.bucket_ranges:
            self.buckets[i] =  execute('SELECT COUNT(*) FROM self.table
                                        WHERE self.column >= range.low
                                        AND self.column <= range.high')
\end{verbatim}

Para calcular la selectividad por igualdad se aproxima utilizando la selectividad promedio del \textit{bucket}, por lo que se divide el número de registros correspondientes a dicha barra por la cantidad total y luego por el \textit{step}.

La función \textit{bucket\_for} retorna el índice del \textit{bucket} correspondiente al valor que se le pasa como parámetro.

\begin{verbatim}
    def estimate_equal(self, value):
        if value > self.max or value < self.min:
            return 0
        bucket = self.buckets[self.bucket_for(value)]
        return bucket / self.step / self.total

\end{verbatim}

Siguiendo la misma idea, para calcular la selectividad por mayor se suman todos los
registros que corresponden a las barras superiores a la que pertenece el elemento, mas los que se estima que son mayores dentro de la misma barra, lo cual se aproxima tomando la mitad de los registros del intervalo. 
%Esto se calcula en base a la diferencia con el limite superior del intervalo que lo contiene, dividiéndola luego por el step.
Luego se le resta a esta estimación, la mitad de la estimación de igualdad para preservar la propiedad de \textbf{consistencia} del estimador.

\begin{verbatim}
    def estimate_greater(self, value):
        if value > self.max:
            return 0
        elif value < self.min:
            return 1
        bucket = self.bucket_for(value)
        greater = self.buckets[bucket] / 2
        for i in [bucket + 1, self.num_buckets):
            greater += self.buckets[i]
        return greater / self.total - self.estimate_equal(value) / 2
\end{verbatim}


\subsection{Distribution Steps}

En este caso se busca obtener un histograma con barras de la misma altura variando el
tamaño de los intervalos que representa cada barra. De esta forma se busca tener mayor
 granularidad en el caso de que para algunos valores tengamos mucha cantidad de
 registros y para otros no. Entonces se arma un histograma dividiendo la cantidad de
 registros de la tabla en N grupos de igual tamaño, siendo N pasado por parámetro al
 inicializarlo. 
 
 En nuestra implementación utilizamos una lista llamada \textit{steps} en la cual, en cada posicion, se guarda el valor mínimo de dicho \textit{bucket}. Luego se agrega un último índice que contiene el valor máximo.
\begin{verbatim}
    def build_struct(self):
        self.items_per_step = ceil(float(self.total) / self.num_steps)
        all_in_order = c.execute('SELECT self.column 
        						FROM self.table 
        						ORDER BY self.column ASC')
        for current_step in [0, self.num_steps):
            if current_step == self.num_steps -1 :
                rows_for_step = c.fetchall()
                self.steps[self.num_steps] = rows_for_step.last.value
            else:
                rows = c.fetchmany(self.items_per_step)
            self.steps[current_step] = rows_for_step.first.value
\end{verbatim}
Luego para calcular la estimación por igualdad se aproxima como tomando como si 1/3 de los elementos del bucket fueran iguales al valor buscado en caso de que no coincida con el límite inferior de ningún intervalo. Si coincide con uno o más límites se aproxima como si todos esos intervalos contuvieran ese valor.
\begin{verbatim}
    def estimate_equal(self, value):
        if value < self.steps[0]:
            return 0
        if value > self.steps[self.num_steps]:
            return 0
        for step in [0, self.num_steps + 1):
            if self.steps[step] > value:
                return 1 / (3 * self.num_steps)
            elif self.steps[step] == value:
                if 0 < step < self.num_steps and self.steps[step + 1] != value:
                    steps_range = self.steps[step+1] - self.steps[step-1]
                    return self.items_per_step * 2.0 / steps_range / self.total
                else:
                    k = 0
                    while len(self.steps) > step + k + 1 and self.steps[step + k + 1] == value:
                        k += 1
                    if 0 < step and self.steps[self.num_steps] != value:
                        return k / self.num_steps
                    else:
                        return (k - 0.5) / self.num_steps
\end{verbatim}
 Para calcular la estimación de elementos mayores se utiliza la propiedad de \textbf{consistencia} del estimador, para así implementaar la estimación por menor, la cual puede realizarse de forma más directa a partir del paper. Por lo tanto el estimador por mayor queda reducido a lo siguiente:
  
 \begin{verbatim}
   def estimate_greater(self, value):
        return 1 - self.estimate_equal(value) - self.estimate_lower(value)
 \end{verbatim}
 Luego la estimación por menor se aproxima tomando como si 1/3 de los
elementos del intervalo al que corresponde el valor fueran menores que éste si el valor que se evalúa no es límite del mismo. En caso contrario se asume que la mitad de los valores del intervalo anterior son menores que el valor.

\begin{verbatim}
def estimate_lower(self, value):
        if value <= self.steps[0]:
            return 0
        if value > self.steps[self.num_steps]:
            return 1
        for step in [0, self.num_steps + 1):
            if self.steps[step] > value:
                return (step + 1.0/3) / self.num_steps
            elif self.steps[step] == value:
                if 0 < step < self.num_steps and self.steps[step+1] != value:
                    return (step - 0.5) / self.num_steps
                else:
                    k = 0
                    while len(self.steps) > step + k + 1 and self.steps[step+k+1] == value:
                        k += 1
                    if 0 < step and self.steps[self.num_steps] != value:
                       return (step - 0.5) / self.num_steps
                    else:
                        return 1 - (k - 0.5) / self.num_steps
\end{verbatim}

\subsection{Estimador Grupo}

En este estimador se busca aprovechar el tipo de histograma que se arma con distribution steps,
pero intentando mejorar principalmente el estimador por igualdad, ya que con una cantidad baja de steps la estimación es bastante grosera, ya que quedan muchos registros por
grupo y generalmente el estimar que 1/3 de ellos son iguales al valor que buscamos trae un error muy grande.
Por lo tanto para estimar la cantidad de elementos iguales a uno dado ,en el caso en que éste no coincida con el límite inferior de un intervalo, se aproxima dividiendo la cantidad de elementos del step
(la cual siempre es la misma) por el rango de valores del step, y luego ésto por la cantidad total de elementos de la base.
En el caso que coincide con sólo un límite inferior, y éste no es el primero ni el último, se toma como si tanto el intervalo anterior como el que representa fueran uno sólo y se realiza el calculo de la misma forma que el primer caso.

El resto de los casos se realizan de forma similar al distribution steps.

\begin{verbatim}
def estimate_equal(self, value):
        if value < self.steps[0]:
            return 0
        if value > self.steps[self.num_steps]:
            return 0
        for step in xrange(self.num_steps+1):
            if self.steps[step] > value:
                step_range = self.steps[step] - self.steps[step-1] +1
                return self.items_per_step/ step_range / self.total
            elif self.steps[step] == value:
                if 0 < step < self.num_steps and self.steps[step+1] != value:
                    steps_range = self.steps[step+1] - self.steps[step-1]
                    return self.items_per_step * 2.0 / steps_range / self.total
                else:
                    k = 0
                    while len(self.steps) > step + k + 1 and self.steps[step+k+1] == value:
                        k += 1
                    if 0 < step and self.steps[self.num_steps] != value:
                        return float(k) / self.num_steps
                    else:
                        return float((k - 0.5) / self.num_steps)

\end{verbatim}

El estimador por mayor valor funciona de forma similar para el caso en que el valor no coincide con el límite inferior de algún intervalo, aproximando linealmente la cantidad de elementos menores al valor dentro del intervalo. Ésto se realiza calculando la diferencia del valor con el límite inferior del intervalo y luego dividiendo ésto por el rango de valores dentro del intervalo.

Además en todos los casos, para preservar la propiedad de consistencia, se modificaron los calculos restando directamente la mitad del valor de la estimación por igual.

\begin{verbatim}
    def estimate_lower(self, value):
        if value < self.steps[0]:
            return 0
        if value > self.steps[self.num_steps]:
            return self.total
        for step in [0, self.num_steps+1):
            if self.steps[step] > value:
                step_range = self.steps[step] - self.steps[step-1] + 1
                factor = float(value - self.steps[step-1]) / step_range
                return (step + factor) / self.num_steps - self.estimate_equal(value) / 2
            elif self.steps[step] == value:
                if 0 < step < self.num_steps and self.steps[step+1] != value:
                    return float(step) / self.num_steps - self.estimate_equal(value) / 2
                else:
                    k = 0
                    while len(self.steps) > step + k + 1 and self.steps[step+k+1] == value:
                        k += 1
                    if 0 < step and self.steps[self.num_steps] != value:
                        return float(step) / self.num_steps - self.estimate_equal(value) / 2
                    else:
                         return 1 - float(k) / self.num_steps - self.estimate_equal(value) / 2                       
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Análisis Teório                                                            %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Análisis Teórico}

\subsection{Dataset con distribucion normal}
El estimador Classic Histogram presentará una reducción de precisión bajo una distribución normal, en especial, a la hora de realizar operaciones de mayor. Esto se debe a lo siguiente:

\begin{itemize}
\item La naturaleza de la distribución implica que se tendrán valores distribuidos en forma de campana, implicando barras de gran altura en el histograma.
\item Para el cálculo de la selectividad mayor, el estimador toma la mitad del intervalo donde cae el valor buscado, más los demás intervalos necesarios, esto concluye con un error de A/2 siendo A la altura de la barra donde se encuentra el valor a buscar.
\item Para la consulta de selectividad por igualdad, se divide la altura de la barra donde cae el valor a estimar por el ancho de la barra y luego por el total de los registros en la relación. Se realiza esta aproximación suponiendo un promedio de elementos en el rango. Eventualmente podrían ser todos los elementos de la barra el que se está buscando, obteniéndose un error máximo de A/Total - (A/Width/Total) siendo A la altura del bucket, Width su ancho y Total la cantidad de registros en la relación.
\end{itemize}

Estos errores máximos basados en la altura de los buckets resultarán en una baja en la pérformance promedio.

Al contrario de Classic Histogram, Distribution Steps debería exhibir una mejor pérformance ante esta distribución en igualdad de \textit{steps} y \textit{barras}. Esto se debe a que no sufre del problema de los bloques de gran altura. Como puede verse en la descripción del estimador, este construye sus \textit{steps} de misma altura, haciendo que el problema antes descripto para Classic Histogram no ocurra, resultando en un error de estimación de la selectividad menor.

El comportamiento de Estimador Grupo será similar a Distribution Steps para las consultas de mayor. En el caso de la igualdad, Estimador Grupo se comporta de manera similar a Classic Histogram, pero no sufre del problema de las columnas altas debido a que todos sus steps tienen igual altura, obteniendo una mejor pérformance en este caso.

Dada las magnitudes posibles de los errores, Distribution Steps debería exhibir un mejor desempeño.

\subsection{Dataset con distribución uniforme}

Debido a la distribución uniforme de los datos en el rango, el estimador Classic Histogram, presentará a la hora de construir sus \textit{barras}, de igual altura. Como mencionamos en el análisis del Dataset de distribución normal, el error que presentará este estimador está ligado con la altura de las barras que posea. Al obtener ahora \textit{barras} de igual altura se elimina la ocurrencia del problema mencionado en el Dataset con distribución normal, el error del cálculo de la selectividad tanto para mayor como para igual se verá disminuido en promedio. 

El estimador Distribution steps no se verá influenciado por el cambio de distribución, siempre distribuye los datos en steps con igual cantidad de registros como mencionamos anteriormente, y tiene un error máximo en el cálculo de la selectividad de 1/S, siendo S la cantidad de steps o el parámetro de la distribución.

Por último, el Estimador Grupo exhibirá un comportamiento similar a Classic Histogram a la hora de realizar la selectividad por igualdad, por lo que obtendrá un resultado considerablemente bueno. Algo similar sucede con el cálculo de selectividad por mayor, el cuál obtendrá los mismos resultados que distribution steps.

En esta distribución, aunque los errores se vean reducidos, el error máximo de Distribution Steps para la selectividad por mayor será menor que el de Classic Histogram e igual que Estimador Grupo, pudiendo ambos estimadores desempeñarse mejor que Classic Histogram.

Por la parte de igualdad, Classic Histogram deberá exhibir buenos resultados. Esto se debe a que, como la distribución de los datos es uniforme y, el cálculo de selectividad para la igualdad es (A/Width/Total), es decir, el promedio de tuplas con el valor buscado que debe haber en la barra, el resultado de la selectividad debería tener una aproximación superior a Distribution Steps y similar o igual a Estimador Grupo por usar el mismo método.

Concluimos que Estimador Grupo deberá tener la mejor pérfomance en este caso.

\subsection{Peores casos para los estimadores}

Por lo discutido anteriormente en la sección del Dataset con distribución normal, Classic Histogram presentará mayor error cuanto mayor sea la variación de tamaño entre alturas de las barras que posea el estimador. Distribuciones que concentren casi la totalidad de sus registros en un solo valor, harán que el estimador posea un barra de gran altura y las demás de baja.

Supongamos una distribución que cumpla con lo mencionado. La distribución a evaluar contiene casi la totalidad de sus registros en un solo valor, al evaluar la selectividad utilizando el estimador, es posible notar lo siguiente:
\begin{itemize}
\item Utilizando el cálculo del error máximo para el cálculo por mayor (A/2), siendo A la altura, y suponiendo que el valor a buscar entre en el intervalo de la barra de mayor altura, el cálculo resulta en un error aproximado de 0.5, maximizando el error posible que se puede obtener en la utilización de este tipo de query de selectividad para el estimador.
\item Para el cálculo por igualdad, ocurre algo similar, al ser el error A/Total - (A/Width/Total), siendo A cercano al valor \textit{Total} de tuplas en la relación el error aproximado será considerablemente alto, cercano a 1, maximizando el error posible.
\end{itemize}

El estimador Distribution Steps es inmune a todo tipo de cambio de distribuciones. El cálculo de su error se base exclusivamente en la cantidad de \textit{steps} o divisiones que posea el estimador en base a su parámetro. No existe una distribución que maximize su error de estimación.

El Estimador Grupo exhibirá para una distribución similar a la presentada para Classic Histogram, un error máximo en el cálculo de selectividad por igualdad. Esto ocurre debido a que realiza un cálculo similar a Classic Histogram basándose en el promedio posible de valores que habrá en el rango de los steps, obteniéndose en el caso de pedir la selectividad por igualdad y al encontrarse el valor buscado dentro de un step que tenga todos valores iguales, el error máximo que podría obtener el estimador para este tipo de selectividad. 

Por último, el Estimador Grupo obtendrá incluso una disminución en precisión para el cálculo por mayor. Si bien es similar a distribution steps, utiliza para algunos casos el cálculo utilizado en Classic Histogram, acarreando parte del error explicado anteriormente.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Análisis Empírico                                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Análisis Empírico}

\subsection{Experimentación}
Para los resultados generados, se utilizaron los estimadores Classic Histogram, Distribution Steps y el Estimador Grupo 
sobre la distribución normal y la distribución uniforme de las figuras \ref{custom-dataset-uniform} y 
\ref{custom-dataset-normal} respectivamente, generadas aleatoriamente. 

Se utilizaron 50 queries para la evaluación de la selectividad en intervalos de 20 (\textbf{Sel(}=0\textbf{)}, \textbf{Sel(}=19\textbf{)}, ...) y se corrieron tanto para la selectividad por igual como para mayor, con valores del parámetro de los estimadores entre 5 y 100 en intervalos de 5.

\subsection{Datasets utilizados}

A continuación se ilustran los datasets utilizados durante el análisis de performance de los estimadores estudiados.

\grafico{custom-dataset-uniform}
        {Distribución uniforme}
        {custom-dataset-uniform}

\grafico{custom-dataset-normal}
        {Distribución normal}
        {custom-dataset-normal}


\subsection{Estimador \texttt{ClassicHistogram}}

\subsubsection{Distribución uniforme}

\grafico{plot-hist-uniform-equal}
        {Distribución uniforme, consulta por igualdad.}
        {plot-hist-uniform-equal}
\grafico{plot-hist-uniform-greater}
        {Distribución uniforme, consulta por mayor.}
        {plot-hist-uniform-greater}

En las figuras \ref{plot-custom-uniform-greater} y \ref{plot-hist-uniform-equal} se pueden observar valores muy bajos
en la pérfomance como se predijo en la sección teórica, acompañados de una gran varianza. En ambas figuras, se puede ver como al iniciar con un valor en parámetro bajo,
la pérformance es más alta, como es de esperarse, ya que, aumentar este valor debería producir una reducción de la pérformance al obtener más precisión.
Atribuímos la gran varianza y anomalías aparentes como pequeñas montañas en los gráficos como pueden verse en los
valores del parámetro 35 y 70 de la figura \ref{plot-hist-uniform-equal} por ejemplo, a errores de punto flotante en el cálculo de la selectividad y en el armado del estimador.
El método de predicción de selectividad elejido para la igualdad genera una pérformance muy baja, obteniéndose resultados satisfactorios y similares para todos los valores probados del parámetro.

\subsubsection{Distribución normal}


\grafico{plot-hist-normal-equal}
        {Distribución normal, consulta por igualdad.}
        {plot-hist-normal-equal}
\grafico{plot-hist-normal-greater}
        {Distribución normal, consulta por mayor.}
        {plot-hist-normal-greater}

Las figuras \ref{plot-hist-normal-equal} y \ref{plot-hist-normal-greater} de selectividad por igualdad y por mayor respectivamente, evidencian la diferencia 
de pérfomance que implica analizar la distribución normal con este estimador.

Como se vió en el análisis teórico anteriormente, la búsqueda de selectividad por mayor, que podía obtener un error máximo 
alto en la selectividad en esta distribución, en especial con valores del parámetro bajo como muestra en la figura \ref{plot-hist-normal-greater} una pérfomance de valor alto, que decrece contínuamente a medida que se incrementa el valor del parámetro, como era de esperarse, debido a que una reducción en el tamaño de los intervalos implica mayor precisión en la selectividad por mayor.

Por el lado de la igualdad, se muestran valores de pérfomance altos, con un varianza alta al utilizar valores bajos del parámetro a comparación de la figura \ref{plot-hist-uniform-equal} donde se utiliza una distribución uniforme. Sin embargo, con sucesivos incrementos en el parámetro, el aumento se precisión evidencia una mejora notable.   

\subsection{Estimador \texttt{DistributionSteps}}


\subsubsection{Distribución uniforme}
\grafico{plot-diststep-uniform-equal}
        {Distribución uniforme, consulta por igualdad.}
        {plot-diststep-uniform-equal}
\grafico{plot-diststep-uniform-greater}
        {Distribución uniforme, consulta por mayor.}
        {plot-diststep-uniform-greater}
De la observación de los resultados presentados en las figuras \ref{plot-diststep-uniform-equal}, \ref{plot-diststep-uniform-greater} se deduce que un valor bajo del parámetro implica valores de pérfomance altos a comparación de la pérfomance obtenida al 
incrementar el parámetro. La curva de pérfomance es de carácter logarítmico inverso, consiguiéndose menor decremento del valor del pérfomance al aproximarse a la selectividad correcta.

Además de esto, podemos notar que el cálculo de igualdad obtiene una mejor aproximación a la selectividad real que el cálculo de la selectividad por mayor.

\subsubsection{Distribución normal}    
\grafico{plot-diststep-normal-equal}
        {Distribución normal, consulta por igualdad.}
        {plot-diststep-normal-equal}
\grafico{plot-diststep-normal-greater}
        {Distribución normal, consulta por mayor.}
        {plot-diststep-normal-greater}

A partir de las figuras \ref{plot-diststep-normal-equal}, \ref{plot-diststep-normal-greater} y comparándolas con las figuras \ref{plot-diststep-uniform-equal} y \ref{plot-diststep-uniform-greater} se puede notar, como se predijo en la sección teórica, que no hay casi diferencia entre utilizar el estimador en una distribución normal o en una distribución uniforme. En ambas distribuciones, se tiene un comportamiento tanto en la performance como la varianza muy similar.

\subsection{Estimador \texttt{EstimadorGrupo}}

\subsubsection{Distribución uniforme}

\grafico{plot-custom-uniform-equal}
        {Distribución uniforme, consulta por igualdad.}
        {plot-custom-uniform-equal}
\grafico{plot-custom-uniform-greater}
        {Distribución uniforme, consulta por mayor.}
        {plot-custom-uniform-greater}

En las figuras \ref{plot-custom-uniform-equal} podemos observar que la mejora en las consultas por igualdad es notable respecto a distribution steps, 
sobre todo para valores bajos del parámetro con ésta distribución. Si bien se nota que tiene una varianza basatante alta con los primeros valores, ésta se reduce en gran medida para valores mas altos.
Por su parte, en \ref{plot-custom-uniform-greater} podemos ver que para consultas por mayor el rendimiento es bastante similar que distribution steps en este caso, pero la varianza se mantiene siempre alta.

\subsubsection{Distribución normal}        

\grafico{plot-custom-normal-equal}
        {Distribución normal, consulta por igualdad.}
        {plot-custom-normal-equal}
\grafico{plot-custom-normal-greater}
        {Distribución normal, consulta por mayor.}
        {plot-custom-normal-greater}

Luego de comparar las figuras \ref{plot-custom-normal-equal} y \ref{plot-custom-normal-greater} con las correspondientes a la distribución uniforme(\ref{plot-custom-uniform-equal} y \ref{plot-custom-uniform-greater}) podemos ver que al igual que el distribution steps, el comportamiento de este algoritmo es muy similar para ambas distribuciones.

\subsection{Datasets provistos por la cátedra}

A continuación ilustramos los datasets correspondientes a cada columna de la tabla en la base de datos provista por la cátedra.

\grafico{dataset-c0}
        {Columna \emph{c0}}
        {dataset-columna-c0}

\grafico{dataset-c1}
        {Columna \emph{c1}}
        {dataset-columna-c1}

\grafico{dataset-c2}
        {Columna \emph{c2}}
        {dataset-columna-c2}

\grafico{dataset-c3}
        {Columna \emph{c3}}
        {dataset-columna-c3}

\grafico{dataset-c4}
        {Columna \emph{c4}}
        {dataset-columna-c4}

\grafico{dataset-c5}
        {Columna \emph{c5}}
        {dataset-columna-c5}

\grafico{dataset-c6}
        {Columna \emph{c6}}
        {dataset-columna-c6}

\grafico{dataset-c7}
        {Columna \emph{c7}}
        {dataset-columna-c7}

\grafico{dataset-c8}
        {Columna \emph{c8}}
        {dataset-columna-c8}

\grafico{dataset-c9}
        {Columna \emph{c9}}
        {dataset-columna-c9}


\subsection{Comparación de eficacia entre estimadores}
Para cada una de las columnas provistas por la cátedra, se realizaron para cada estimador, para las selectividades de mayor e igual y para diferentes valores en el parámetros de los estimadores, \textit{Student’s T-Test Apareados} con el objetivo de determinar como varía el p-valor en la comparaciones de pérformance entre los estimadores para estas variables.

El test se realizó en condiciones similares a la experimentación realizada para visualizar la pérfomance de los estimadores bajo las distribuciones normal y uniforme, utilizando aproximadamente 50 queries para cada uno de los 10 valores del parámetro de los estimadores utilizados, para luego usar esa información con las funciones que provee \textit{SciPy} para realizar los \textit{Student’s T-Test Apareados}.

Las comparaciones que no son fácilmente visualizables en los gráficos muestran un p-valor extremadamente pequeño, implicando una significancia importante.

Se traza en los gráficos una línea \textit{dashed} en 0.05 para reflejar el umbral de aceptación. Toda comparación por debajo de esta línea aprobaría la diferencia de pérformance entre ambos estimadores.

\grafico{plot-significance-c0}
        {Significancia en pérformance entre estimadores para la columna \emph{c0}}
        {student-columna-c0}

\grafico{plot-significance-c1}
        {Significancia en pérformance entre estimadores para la columna \emph{c1}}
        {student-columna-c1}

\grafico{plot-significance-c2}
        {Significancia en pérformance entre estimadores para la columna \emph{c2}}
        {student-columna-c2}

\grafico{plot-significance-c3}
        {Significancia en pérformance entre estimadores para la columna \emph{c3}}
        {student-columna-c3}

\grafico{plot-significance-c4}
        {Significancia en pérformance entre estimadores para la columna \emph{c4}}
        {student-columna-c4}

\grafico{plot-significance-c5}
        {Significancia en pérformance entre estimadores para la columna \emph{c5}}
        {student-columna-c5}

\grafico{plot-significance-c6}
        {Significancia en pérformance entre estimadores para la columna \emph{c6}}
        {student-columna-c6}

\grafico{plot-significance-c7}
        {Significancia en pérformance entre estimadores para la columna \emph{c7}}
        {student-columna-c7}

\grafico{plot-significance-c8}
        {Significancia en pérformance entre estimadores para la columna \emph{c8}}
        {student-columna-c8}

\grafico{plot-significance-c9}
        {Significancia en pérformance entre estimadores para la columna \emph{c9}}
        {student-columna-c9}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Discusión                                                                  %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Discusión}

%En base al analisis previo y la experimentacion realizada sobre los estimadores discutir qu e metodo es mejor para cada tipo de distribucion de datos.
Luego de realizar las pruebas previamente expuestas y de analizar los resultados arrojados por las mismas pudimos observar que el algoritmo de \textit{Classic Histogram}
tiene un muy buen comportamiento sólo para la distribución uniforme, en especial para valores bajos del parámetro. Por otro lado, para dicha distribución el algoritmo de \textit{Distribution Steps} tiene una performance muy mala para valores bajos del parámetro y luego mejora con valores mayores. Nuestro estimador mejora ese aspecto con respecto al \textit{Distribution Steps}, pero sin llegar a ser como \textit{Classic Histogram}. Por lo tanto para este tipo de distribuciones el de mejor comportameinto es sin dudas el \textit{Classic Histogram}. Esta relación está respaldada por la figura \ref{student-columna-c0} que evidencia que los resultados entre \textit{Classic Histogram} y \textit{Distribution Steps} son significativos para la columna C0 de distribución uniforme.

Para distribuciones con valores mas irregulares en cambio, la performance de \textit{Classic Histogram} se degrada mucho y se observa a su vez un aumento de la varianza en sus estimaciones. Variaciones especiales como las descriptas en el análisis teórico influencian tanto a \textit{Classic Histogram} como al \textit{Estimador Grupo}, pero el rendimiento de este último es notablemente mejor. Por otro lado el rendimiento de \textit{Distribution Steps} se mantiene igual para las diferentes distribuciones. El \textit{Estimador Grupo} presenta mejores estimaciones en general, para los casos donde no existe una gran concentración de valores, superando a \textit{Distribution Steps}.

Por estos motivos, si no se tiene ningún conocimiento sobre las distribuciones, el algoritmo de \textit{Distribution Steps} es la mejor opción, ya que su error máximo siempre estará acotado por la cantidad de \textit{steps} que posea y no por los valores de las distribuciones.

Para el caso de que se tenga conocimiento sobre la distribución, y esta no posea una concentración importante de datos entorno a un solo valor, concluimos que el \textit{Estimador Grupo} resolverá en mejor medida tanto las consultas de igualdad como por mayor.
%Comentar si existe un m etodo que se comporte mejor para el caso general (un dataset con distribuci ́on desconocida).
%Discutir qúe otros factores hay que tener en cuenta para emplear los estimadores, por ejemplo, tiempo de construcci ́on, costo de mantenimiento, etc.

Otros factores a tener en cuenta para la utilización de los estimadores son, por ejemplo, el tiempo de construcción y el costo de mantenimiento del mismo.
En el caso del \textit{Classic Histogram}, el costo de construcción es bastante bajo, básicamente se realiza una consulta que cuenta la cantidad de registros cuyo valor está en determinado rango, para cada uno de los rangos de valores correspondientes a las barras del histograma. Luego para actualizarlo en caso de inserción o borrado se sumo o resta 1 a la columna a la cual corresponde el valor correspondiente a ese registro.
Esto supone un costo muy bajo tanto de creación como de mantenimiento.

Por el otro lado, para construir las estructuras de los otros estimadores primero se debe ordenar la tabla entera y luego ir leyendo todos los registros de la bloques. esto supone un costo mucho mas alto de construcción. Además al momento de actualizar si se quiere mantener igualado la altura de las barras se deben recomputar todo periódicamente, ya que sólo se almacenan los valores mínimos de cada step.

Por lo tanto, si la base de datos va a tener una gran cantidad de actualizaciones puede que el uso de histogramas de barras de igual altura se haga insostenible.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Conclusiones                                                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Conclusiones}
A lo largo de este trabajo pudimos apreciar distintos maneras de implementar estimadores para la selectividad de las consultas a una base de datos.
El objetivo del desarrollo de los mismos es el de usar la información que proveen para optimizar las consultas a la base y así responder con mayor velocidad. Por lo tanto, un requisito fundamental de los estimadores es que su respuesta sea rápida, por lo cual debe realizar cálculos simples para obtenerla. Asimismo se espera que la misma sea lo más precisa posible, ya que de caso contrario sería igualmente inútil. Teniendo en cuenta además que si la base sufre cambios en sus valores los estimadores deben adaptarse a ellos para seguir siendo precisos sin que dicha tarea consuma demasiados recursos que podrían dedicarse a las búsquedas.

Planteados estos requerimientos, se pudieron observar distintos enfoques que cumplen en mayor o menor medida con cada uno de ellos.

Concluimos en que, la elección de los estimadores dependerá en mayor medida de el uso que se le dé a la base de datos y del conocimiento que se tenga sobre la misma. Estimadores como \textit{Distirbution Steps} y \textit{Estimador Grupo} ofrecen una buena precisión para distribuciones desconocidas, en especial \textit{Distirbution Steps}, pero la creación del estimador puede ser costosa al necesitar un ordenamiento de las tuplas, haciéndose difícil su utilización en bases de datos de gran tamaño con variaciones continuas la misma, ya que sería difícil de mantener. El estimador \textit{Classic Histogram} puede ofrecer buenas aproximaciones cuando la distribución tiende a la uniformidad, pero presentará una disminución de la precisión importante en distribuciones donde los valores estén concentrados. A pesar de esto \textit{Classic Histogram} es ideal para bases de datos de gran tamaño, ya que su mantenimiento es muy barato.

\end{document}
