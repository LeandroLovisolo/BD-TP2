\documentclass[a4paper, 10pt, twoside]{article}

\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[spanish, es-ucroman, es-noquoting]{babel}
\usepackage{setspace}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{verbatim}
\usepackage{fancyvrb}
\usepackage{graphicx}
\usepackage{float}
\usepackage{enumitem} % Provee macro \setlist
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{xspace}
\usepackage{makeidx}
\usepackage[toc, page]{appendix}

\makeindex

%%%%%%%%%% Constantes - Inicio %%%%%%%%%%
\newcommand{\titulo}{Trabajo Práctico 2}
\newcommand{\materia}{Bases de Datos}
\newcommand{\integrantes}{Delgado · Lovisolo · Petaccio · Rebecchi}
\newcommand{\cuatrimestre}{Segundo Cuatrimestre de 2014}
%%%%%%%%%% Constantes - Fin %%%%%%%%%%


%%%%%%%%%% Configuración de Fancyhdr - Inicio %%%%%%%%%%
\pagestyle{fancy}
\thispagestyle{fancy}
\lhead{\titulo\ · \materia}
\rhead{\integrantes}
\renewcommand{\footrulewidth}{0.4pt}
\cfoot{\thepage /\pageref{LastPage}}

\fancypagestyle{caratula} {
   \fancyhf{}
   \cfoot{\thepage /\pageref{LastPage}}
   \renewcommand{\headrulewidth}{0pt}
   \renewcommand{\footrulewidth}{0pt}
}
%%%%%%%%%% Configuración de Fancyhdr - Fin %%%%%%%%%%


%%%%%%%%%% Insertar gráfico - Inicio %%%%%%%%%%
\newcommand{\grafico}[3]{
  \begin{figure}[H]
    \includegraphics[type=pdf,ext=.pdf,read=.pdf]{#1}
    \caption{#2}
    \label{#3}
  \end{figure}
}
%%%%%%%%%% Insertar gráfico - Fin %%%%%%%%%%


%%%%%%%%%% Miscelánea - Inicio %%%%%%%%%%
% Evita que el documento se estire verticalmente para ocupar el espacio vacío
% en cada página.
\raggedbottom

% Separación entre párrafos.
\setlength{\parskip}{0.5em}

% Separación entre elementos de listas.
\setlist{itemsep=0.5em}

% Asigna la traducción de la palabra 'Appendices'.
\renewcommand{\appendixtocname}{Apéndices}
\renewcommand{\appendixpagename}{Apéndices}
%%%%%%%%%% Miscelánea - Fin %%%%%%%%%%


\begin{document}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Carátula                                                                   %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\thispagestyle{caratula}

\begin{center}

\includegraphics[height=2cm]{DC.png} 
\hfill
\includegraphics[height=2cm]{UBA.jpg} 

\vspace{2cm}

Departamento de Computación,\\
Facultad de Ciencias Exactas y Naturales,\\
Universidad de Buenos Aires

\vspace{4cm}

\begin{Huge}
\titulo
\end{Huge}

\vspace{0.5cm}

\begin{Large}
\materia
\end{Large}

\vspace{1cm}

\cuatrimestre

\vspace{4cm}

\begin{tabular}{|c|c|c|}
\hline
Apellido y Nombre & LU & E-mail\\
\hline
Delgado, Alejandro N.  & 601/11 & nahueldelgado@gmail.com\\
Lovisolo, Leandro      & 645/11 & leandro@leandro.me\\
Petaccio, Lautaro José & 443/11 & lausuper@gmail.com\\
Rebecchi, Alejandro    & 15/10  & alejandrorebecchi@gmail.com\\
\hline
\end{tabular}

\end{center}

\newpage

\printindex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Introducción                                                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Introducción}

Este trabajo introduce tres estimadores de selectividad distintos, Classic Histogram, Distribution Steps provistos 
por el paper\footnote{G. Piatetsky-Shapiro and C. Connell. Accurate estimation of the number of tuples satisfying
a condition. Proc. of ACM SIGMOD Conf. pages 256-276, 1984} otorgado por la cátedra y Estimador Grupo creado por 
los participantes del trabajo. El trabajo presenta un análisis teórico y empírico del comportamiento de estos 
estimadores ante diferentes situaciones y presenta los resultados y conclusiones de los mismos.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Estimadores                                                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Estimadores}

\subsection{Classic Histogram}

Este estimador se basa en un modelo de histograma en el cual cada barra representa un rango
de valores del mismo tamaño.
Es decir, al inicializar el estimador, se le pasa como parámetro el numero de barras que se
desea que tenga el histograma
y luego se utiliza dicho valor para dividir el rango de valores en partes iguales.
Esto se realiza al inicializar el estimador en la función \textit{build\_struct}, la cual a su vez delega esta tarea
a otras 3 funciones:
\begin{itemize}
\item \textbf{compute\_range}: La cual calcula la cantidad de valores que abarcará cada barra. Al conjunto de valores asociado
a cada barra lo llamamos \textit{bucket} y la cantidad de elementos que contiene \textit{step}.
\begin{verbatim}
    def compute_range(self):
    	#evita que haya mas buckets que valores
        self.num_buckets = min(self.parameter, self.max - self.min + 1)
        self.step        = float(self.max - self.min) / self.num_buckets
\end{verbatim}
\item \textbf{compute\_bucket\_ranges} En donde se calcula para cada barra, los límites del intervalo de valores
que abarca.
\begin{verbatim}
    def compute_bucket_ranges(self):
        for i in [0..self.num_buckets):
            low  = self.min + int(self.step * i)
            high = self.min + int(self.step * (i + 1)) - 1
            if i == self.num_buckets - 1:
                high = self.max
            bucket_ranges[i] = (low, high)
\end{verbatim}
\item \textbf{compute\_buckets} Se encarga de computar para cada intervalo la cantidad de registros cuyo valor está dentro del mismo.   
\end{itemize}
\begin{verbatim}
    def compute_buckets(self):
        for range in self.bucket_ranges:
            self.buckets[i] =  execute('SELECT COUNT(*) FROM self.table
                                        WHERE self.column >= range.low
                                        AND self.column <= range.high')
\end{verbatim}

Para calcular la selectividad por igualdad se aproxima utilizando la selectividad promedio del \textit{bucket}, por lo que se divide el número de registros correspondientes a dicha barra por la cantidad total y luego por el \textit{step}.

La función \textit{bucket\_for} retorna el índice del \textit{bucket} correspondiente al valor que se le pasa como parámetro.

\begin{verbatim}
    def estimate_equal(self, value):
        if value > self.max or value < self.min:
            return 0
        bucket = self.buckets[self.bucket_for(value)]
        return bucket / self.step / self.total

\end{verbatim}

Siguiendo la misma idea, para calcular la selectividad por mayor se suman todos los
registros que corresponden a las barras superiores a la que pertenece el elemento, mas los que se estima que son mayores dentro de la misma barra, lo cual se aproxima tomando la mitad de los registros del intervalo. 
%Esto se calcula en base a la diferencia con el limite superior del intervalo que lo contiene, dividiéndola luego por el step.
Luego se le resta a esta estimación, la mitad de la estimación de igualdad para preservar la propiedad de \textbf{consistencia} del estimador.

\begin{verbatim}
    def estimate_greater(self, value):
        if value > self.max:
            return 0
        elif value < self.min:
            return 1
        bucket = self.bucket_for(value)
        greater = self.buckets[bucket] / 2
        for i in [bucket + 1, self.num_buckets):
            greater += self.buckets[i]
        return greater / self.total - self.estimate_equal(value) / 2
\end{verbatim}


\subsection{Distribution Steps}

En este caso se busca obtener un histograma con barras de la misma altura variando el
tamaño de los intervalos que representa cada barra. De esta forma se busca tener mayor
 granularidad en el caso de que para algunos valores tengamos mucha cantidad de
 registros y para otros no. Entonces se arma un histograma dividiendo la cantidad de
 registros de la tabla en N grupos de igual tamaño, siendo N pasado por parámetro al
 inicializarlo. 
 
 En nuestra implementación utilizamos una lista llamada \textit{steps} en la cual, en cada posicion, se guarda el valor mínimo de dicho \textit{bucket}. Luego se agrega un último índice que contiene el valor máximo.
\begin{verbatim}
    def build_struct(self):
        self.items_per_step = ceil(float(self.total) / self.num_steps)
        all_in_order = c.execute('SELECT self.column 
        						FROM self.table 
        						ORDER BY self.column ASC')
        for current_step in [0, self.num_steps):
            if current_step == self.num_steps -1 :
                rows_for_step = c.fetchall()
                self.steps[self.num_steps] = rows_for_step.last.value
            else:
                rows = c.fetchmany(self.items_per_step)
            self.steps[current_step] = rows_for_step.first.value
\end{verbatim}
Luego para calcular la estimación por igualdad se aproxima como tomando como si 1/3 de los elementos del bucket fueran iguales al valor buscado en caso de que no coincida con el límite inferior de ningún intervalo. Si coincide con uno o más límites se aproxima como si todos esos intervalos contuvieran ese valor.
\begin{verbatim}
    def estimate_equal(self, value):
        if value < self.steps[0]:
            return 0
        if value > self.steps[self.num_steps]:
            return 0
        for step in [0, self.num_steps + 1):
            if self.steps[step] > value:
                return 1 / (3 * self.num_steps)
            elif self.steps[step] == value:
                if 0 < step < self.num_steps and self.steps[step + 1] != value:
                    steps_range = self.steps[step+1] - self.steps[step-1]
                    return self.items_per_step * 2.0 / steps_range / self.total
                else:
                    k = 0
                    while len(self.steps) > step + k + 1 and self.steps[step + k + 1] == value:
                        k += 1
                    if 0 < step and self.steps[self.num_steps] != value:
                        return k / self.num_steps
                    else:
                        return (k - 0.5) / self.num_steps
\end{verbatim}
 Para calcular la estimación de elementos mayores se utiliza la propiedad de \textbf{consistencia} del estimador, para así implementaar la estimación por menor, la cual puede realizarse de forma más directa a partir del paper. Por lo tanto el estimador por mayor queda reducido a lo siguiente:
  
 \begin{verbatim}
   def estimate_greater(self, value):
        return 1 - self.estimate_equal(value) - self.estimate_lower(value)
 \end{verbatim}
 Luego la estimación por menor se aproxima tomando como si 1/3 de los
elementos del intervalo al que corresponde el valor fueran menores que éste si el valor que se evalúa no es límite del mismo. En caso contrario se asume que la mitad de los valores del intervalo anterior son menores que el valor.

\begin{verbatim}
def estimate_lower(self, value):
        if value <= self.steps[0]:
            return 0
        if value > self.steps[self.num_steps]:
            return 1
        for step in [0, self.num_steps + 1):
            if self.steps[step] > value:
                return (step + 1.0/3) / self.num_steps
            elif self.steps[step] == value:
                if 0 < step < self.num_steps and self.steps[step+1] != value:
                    return (step - 0.5) / self.num_steps
                else:
                    k = 0
                    while len(self.steps) > step + k + 1 and self.steps[step+k+1] == value:
                        k += 1
                    if 0 < step and self.steps[self.num_steps] != value:
                       return (step - 0.5) / self.num_steps
                    else:
                        return 1 - (k - 0.5) / self.num_steps
\end{verbatim}

\subsection{Estimador Grupo}

En este estimador se busca aprovechar el tipo de histograma que se arma con distribution steps,
pero intentando mejorar principalmente el estimador por igualdad, ya que con una cantidad baja de steps la estimación es bastante grosera, ya que quedan muchos registros por
grupo y generalmente el estimar que 1/3 de ellos son iguales al valor que buscamos trae un error muy grande.
Por lo tanto para estimar la cantidad de elementos iguales a uno dado ,en el caso en que éste no coincida con el límite inferior de un intervalo, se aproxima dividiendo la cantidad de elementos del step
(la cual siempre es la misma) por el rango de valores del step, y luego ésto por la cantidad total de elementos de la base.

\begin{verbatim}
def estimate_equal(self, value):
        if value < self.steps[0]:
            return 0
        if value > self.steps[self.num_steps]:
            return 0
        for step in xrange(self.num_steps+1):
            if self.steps[step] > value:
                step_range = self.steps[step] - self.steps[step-1] +1
                return self.items_per_step/ step_range / self.total
            elif self.steps[step] == value:
                if 0 < step < self.num_steps and self.steps[step+1] != value:
                    return 1.0 / self.total
                else:
                    k = 0
                    while len(self.steps) > step + k + 1 and self.steps[step+k+1] == value:
                        k += 1
                    if 0 < step and self.steps[self.num_steps] != value:
                        return float(k) / self.num_steps
                    else:
                        return float((k - 0.5) / self.num_steps)

\end{verbatim}

El estimador por mayor valor funciona de forma similar para el caso en que el valor no coincide con el límite inferior de algún intervalo, aproximando linealmente la cantidad de elementos menores al valor dentro del intervalo. Ésto se realiza calculando la diferencia del valor con el límite inferior del intervalo y luego dividiendo ésto por el rango de valores dentro del intervalo.

Además en todos los casos, para preservar la propiedad de consistencia, se modificaron los calculos restando directamente la mitad del valor de la estimación por igual.

\begin{verbatim}
    def estimate_lower(self, value):
        if value < self.steps[0]:
            return 0
        if value > self.steps[self.num_steps]:
            return self.total
        for step in [0, self.num_steps+1):
            if self.steps[step] > value:
                step_range = self.steps[step] - self.steps[step-1] + 1
                factor = float(value - self.steps[step-1]) / step_range
                return (step + factor) / self.num_steps - self.estimate_equal(value) / 2
            elif self.steps[step] == value:
                if 0 < step < self.num_steps and self.steps[step+1] != value:
                    return float(step) / self.num_steps - self.estimate_equal(value) / 2
                else:
                    k = 0
                    while len(self.steps) > step + k + 1 and self.steps[step+k+1] == value:
                        k += 1
                    if 0 < step and self.steps[self.num_steps] != value:
                        return float(step) / self.num_steps - self.estimate_equal(value) / 2
                    else:
                         return 1 - float(k) / self.num_steps - self.estimate_equal(value) / 2                       
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Análisis Teório                                                            %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Análisis Teórico}

\subsection{Dataset con distribucion normal}
El estimador Classic Histogram presentará una reducción de precisión bajo una distribución normal, en especial, a la hora de realizar operaciones de mayor. Esto se debe a lo siguiente:

\begin{itemize}
\item La naturaleza de la distribución implica que se tendrán valores distribuídos en forma de campana, implicando barras de gran altura en el histograma.
\item Para el cálculo de la selectividad mayor, el estimador toma la mitad del intervalo donde cae el valor buscado, más los demás intervalos necesarios, esto concluye con un error de A/2 siendo A la altura de la barra donde se encuentra el valor a buscar.
\item Para la consulta de selectividad por igualdad, se divide la altura de la barra donde cae el valor a estimar por el ancho de la barra y luego por el total de los registros en la relación. Se realiza esta aproximación suponiendo un promedio de elementos en el rango. Eventualmente podrían ser todos los elementos de la barra el que se está buscando, obteniendose un error máximo de A/Total - (A/Width/Total) siendo A la altura del bucket, Width su ancho y Total la cantidad de registros en la relación.
\end{itemize}

Estos errores máximos basados en la altura de los buckets resultarán en una baja en la pérformance promedio.

Al contrario de Classic Histogram, Distribution Steps debería exhibir una mejor pérformance ante esta distribución en igualdad de \textit{steps} y \textit{barras}. Esto se debe a que no sufre del problema de los bloques de gran altura. Como puede verse en la descripción del estimador, este construye sus \textit{steps} de misma altura, haciendo que el problema antes descripto para Classic Histogram no ocurra, resultando en un error de estimación de la selectividad menor.

El comportamiento de Estimador Grupo será idéntico a Distribution Steps para las consultas de mayor. En el caso de la igualdad, Estimador Grupo se comporta de manera similar a Classic Histogram, pero no sufre del problema de las columnas altas debido a que todos sus steps tienen igual altura, obteniendo una mejor pérformance en este caso.

Dada las magnitudes posibles de los errores, Distribution Steps debería exhibir un mejor desempeño.

\subsection{Dataset con distribución uniforme}

Debido a la distribución uniforme de los datos en el rango, el estimador Classic Histogram, presentará a la hora de construir sus \textit{barras}, de igual altura. Como mencionamos en el análisis del Dataset de distribución normal, el error que presentará este estimador está ligado con la altura de las barras que posea. Al obtener ahora \textit{barras} de igual altura se elimina la ocurrencia del problema mencionado en el Dataset con distribución normal, el error del cálculo de la selectividad tanto para mayor como para igual se verá disminuído en promedio. 

El estimador Distribution steps no se verá influenciado por el cambio de distribución, siempre distribuye los datos en steps con igual cantidad de registros como mencionamos anteriormente, y tiene un error máximo en el cálculo de la selectividad de 1/S, siendo S la cantidad de steps o el parámetro de la distribución.

Por último, el Estimador Grupo exhibirá un comportamiento similar a Classic Histogram a la hora de realizar la selectividad por igualdad, por lo que obtendrá el mismo error máximo en esta consulta. Lo mismo sucede con el cálculo de selectividad por mayor, el cuál obtendrá los mismos resultados que distribution steps.

En esta distribución, aunque los errores se vean reducidos, el error máximo de Distribution Steps para la selectividad por mayor será menor que el de Classic Histogram e igual que Estimador Grupo, pudiendo ambos estimadores desempeñarse mejor que Classic Histogram.

Por la parte de igualdad, Classic Histogram deberá exhibir buenos resultados. Esto se debe a que, como la distribución de los datos es uniforme y, el cálculo de selectividad para la igualdad es (A/Width/Total), es decir, el promedio de tuplas con el valor buscado que debe haber en la barra, el resultado de la selectividad debería tener una aproximación superior a Distribution Steps y similar o igual a Estimador Grupo por usar el mismo método.

Concluimos que Estimador Grupo deberá tener la mejor pérfomance en este caso.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Análisis Empírico                                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Análisis Empírico}

\subsection{Experimentación}
Para los resultados generados, se utilizaron los estimadores Classic Histogram, Distribution Steps y el Estimador Grupo 
sobre la distribución normal y la distribución uniforme de las figuras \ref{custom-dataset-uniform} y 
\ref{custom-dataset-normal} respectivamente, generadas aleatoriamente. 

Se utilizaron 50 queries para la evaluación de la selectividad en intervalos de 20 (\textbf{Sel(}=0\textbf{)}, \textbf{Sel(}=19\textbf{)}, ...) y se corrieron tanto para la selectividad por igual como para mayor, con valores del parámetro de los estimadores entre 5 y 100 en intervalos de 5.

\subsection{Datasets utilizados}

A continuación se ilustran los datasets utilizados durante el análisis de performance de los estimadores estudiados.

\grafico{custom-dataset-uniform}
        {Distribución uniforme}
        {custom-dataset-uniform}

\grafico{custom-dataset-normal}
        {Distribución normal}
        {custom-dataset-normal}


\subsection{Estimador \texttt{ClassicHistogram}}

\subsubsection{Distribución uniforme}

\grafico{plot-hist-uniform-equal}
        {Distribución uniforme, consulta por igualdad.}
        {plot-hist-uniform-equal}
\grafico{plot-hist-uniform-greater}
        {Distribución uniforme, consulta por mayor.}
        {plot-hist-uniform-greater}

En las figuras \ref{plot-custom-uniform-greater} y \ref{plot-hist-uniform-equal} se pueden observar valores muy bajos
en la pérfomance, acompañados de una gran varianza. En ambas figuras, se puede ver como al iniciar con un valor en parámetro bajo,
la pérformance es más alta, como es de esperarse, ya que, aumentar este valor debería producir una reducción de la pérformance al obtener más precisión.
Atribuímos la gran varianza y anomalías aparentes como pequeñas montañas en los gráficos como pueden verse en los
valores del parámetro 35 y 70 de la figura \ref{plot-hist-uniform-equal} por ejemplo, a errores de punto flotante en el cálculo de la selectividad y en el armado del estimador.
El método de predicción de selectividad elejido para la igualdad genera una pérformance muy baja, obteniéndose resultados satisfactorios y similares para todos los valores probados del parámetro.

\subsubsection{Distribución normal}


\grafico{plot-hist-normal-equal}
        {Distribución normal, consulta por igualdad.}
        {plot-hist-normal-equal}
\grafico{plot-hist-normal-greater}
        {Distribución normal, consulta por mayor.}
        {plot-hist-normal-greater}

Las figuras \ref{plot-hist-normal-equal} y \ref{plot-hist-normal-greater} de selectividad por igualdad y por mayor respectivamente, evidencian la diferencia 
de pérfomance que implica analizar la distribución normal con este estimador.

Como se vió en el análisis teórico anteriormente, la búsqueda de selectividad por mayor, que podía obtener un error máximo 
alto en la selectividad en esta distribución, en especial con valores del parámetro bajo, muestra en la figura \ref{plot-hist-normal-greater} una pérfomance alta 
que decrece contínuamente a medida que se incrementa el valor del parámetro, como era de esperarse, debido a que intervalos más chicos implican 
mayor precisión en la selectividad por mayor.

Por el lado de la igualdad, se muestra una pérfomance alta con un varianza alta con valores bajos del parámetro a comparación de la figura \ref{plot-hist-uniform-equal} 
donde se utiliza una distribución uniforme. Sin embargo, con sucesivos incrementos en el parámetro, el aumento se precisión evidencia una mejora notable.   

\subsection{Estimador \texttt{DistributionSteps}}

\grafico{plot-diststep-uniform-equal}
        {Distribución uniforme, consulta por igualdad.}
        {plot-diststep-uniform-equal}
\grafico{plot-diststep-uniform-greater}
        {Distribución uniforme, consulta por mayor.}
        {plot-diststep-uniform-greater}

\grafico{plot-diststep-normal-equal}
        {Distribución normal, consulta por igualdad.}
        {plot-diststep-normal-equal}
\grafico{plot-diststep-normal-greater}
        {Distribución normal, consulta por mayor.}
        {plot-diststep-normal-greater}

De la observación de los resultados presentados en las figuras \ref{plot-diststep-uniform-equal}, \ref{plot-diststep-uniform-greater}, 
\ref{plot-diststep-normal-equal}, \ref{plot-diststep-normal-greater} se puede ver que no hay casi diferencia entre utilizar el estimador 
en una distribución normal o en una distribución uniforme.

En ambas distribuciones, un valor bajo del parámetro implica una pérfomance alta a comparación de la pérfomance obtenida al 
incrementar el parámetro. La curva de pérfomance es de carácter logarítmico inverso, siendo las diferencias en pérfomance más bajas
al aproximarse a la selectividad correcta.

Por último, puede notarse que en ambas distribuciones, el cálculo de igualdad obtiene una mejor aproximación a la selectividad real 
que para el cálculo de la selectividad por mayor.

\subsection{Estimador \texttt{EstimadorGrupo}}

\grafico{plot-custom-uniform-equal}
        {Distribución uniforme, consulta por igualdad.}
        {plot-custom-uniform-equal}
\grafico{plot-custom-uniform-greater}
        {Distribución uniforme, consulta por mayor.}
        {plot-custom-uniform-greater}
\grafico{plot-custom-normal-equal}
        {Distribución normal, consulta por igualdad.}
        {plot-custom-normal-equal}
\grafico{plot-custom-normal-greater}
        {Distribución normal, consulta por mayor.}
        {plot-custom-normal-greater}


\subsection{Datasets provistos por la cátedra}

A continuación ilustramos los datasets correspondientes a cada columna de la tabla en la base de datos provista por la cátedra.

\grafico{dataset-c0}
        {Columna \emph{c0}}
        {dataset-columna-c0}

\grafico{dataset-c1}
        {Columna \emph{c1}}
        {dataset-columna-c1}

\grafico{dataset-c2}
        {Columna \emph{c2}}
        {dataset-columna-c2}

\grafico{dataset-c3}
        {Columna \emph{c3}}
        {dataset-columna-c3}

\grafico{dataset-c4}
        {Columna \emph{c4}}
        {dataset-columna-c4}

\grafico{dataset-c5}
        {Columna \emph{c5}}
        {dataset-columna-c5}

\grafico{dataset-c6}
        {Columna \emph{c6}}
        {dataset-columna-c6}

\grafico{dataset-c7}
        {Columna \emph{c7}}
        {dataset-columna-c7}

\grafico{dataset-c8}
        {Columna \emph{c8}}
        {dataset-columna-c8}

\grafico{dataset-c9}
        {Columna \emph{c9}}
        {dataset-columna-c9}


\subsection{Comparación de eficacia entre estimadores}
Para cada una de las columnas provistas por la cátedra, se realizaron para cada estimador, para las selectividades de mayor e igual y para diferentes valores en el parámetros de los estimadores, \textit{Student’s T-Test Apareados} con el objetivo de determinar como varía el p-valor en la comparaciones de pérformance entre los estimadores para estas variables.

El test se realizó en condiciones similares a la experimentación realizada para visualizar la pérfomance de los estimadores bajo las distrubiciones normal y uniforme, utilizando aproximadamente 50 queries para cada uno de los 10 valores del parámetro de los estimadores utilizados, para luego usar esa información con las funciones que provee \textit{SciPy} para realizar los \textit{Student’s T-Test Apareados}.

Las comparaciones que no son fácilmente visualizables en los gráficos muestran un p-valor extremadamente pequeño, implicando una significancia importante.

Se traza en los gráficos una línea \textit{dashed} en 0.05 para reflejar el umbral de aceptación. Toda comparación por debajo de esta línea aprobaría la diferencia de pérformance entre ambos estimadores.

\grafico{plot-significance-c0}
        {Significancia en pérformance entre estimadores para la columna \emph{c0}}
        {student-columna-c0}

\grafico{plot-significance-c1}
        {Significancia en pérformance entre estimadores para la columna \emph{c1}}
        {student-columna-c1}

\grafico{plot-significance-c2}
        {Significancia en pérformance entre estimadores para la columna \emph{c2}}
        {student-columna-c2}

\grafico{plot-significance-c3}
        {Significancia en pérformance entre estimadores para la columna \emph{c3}}
        {student-columna-c3}

\grafico{plot-significance-c4}
        {Significancia en pérformance entre estimadores para la columna \emph{c4}}
        {student-columna-c4}

\grafico{plot-significance-c5}
        {Significancia en pérformance entre estimadores para la columna \emph{c5}}
        {student-columna-c5}

\grafico{plot-significance-c6}
        {Significancia en pérformance entre estimadores para la columna \emph{c6}}
        {student-columna-c6}

\grafico{plot-significance-c7}
        {Significancia en pérformance entre estimadores para la columna \emph{c7}}
        {student-columna-c7}

\grafico{plot-significance-c8}
        {Significancia en pérformance entre estimadores para la columna \emph{c8}}
        {student-columna-c8}

\grafico{plot-significance-c9}
        {Significancia en pérformance entre estimadores para la columna \emph{c9}}
        {student-columna-c9}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Discusión                                                                  %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Discusión}

Pendiente.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Conclusiones                                                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Conclusiones}

Pendiente.


\end{document}
